<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>Write operators in Java with JOSDK, Part 4: Upgrading strategies</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/09/19/write-operators-java-josdk-part-4-upgrading-strategies" /><author><name>Christophe Laprun</name></author><id>5a7e37cf-e472-4465-8b2f-4226bbc93d45</id><updated>2023-09-19T07:00:00Z</updated><published>2023-09-19T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://javaoperatorsdk.io"&gt;Java Operator SDK&lt;/a&gt;(JOSDK) is an open source project that aims to simplify the task of creating Kubernetes operators using Java. &lt;a href="https://container-solutions.com"&gt;Container Solutions&lt;/a&gt; started the project, and Red Hat is now a major contributor. The JOSDK project now lives under the &lt;a href="https://github.com/operator-framework"&gt;Operator Framework umbrella&lt;/a&gt;, which is a &lt;a href="https://cncf.io"&gt;Cloud Native Computing Foundation (CNCF)&lt;/a&gt; incubating project.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://developers.redhat.com/articles/2022/02/15/write-kubernetes-java-java-operator-sdk"&gt;first article in this series&lt;/a&gt; introduced JOSDK and explained why it could be interesting to create operators in Java. The &lt;a href="https://developers.redhat.com/articles/2022/03/22/write-kubernetes-java-java-operator-sdk-part-2"&gt;second article&lt;/a&gt; showed how the &lt;a href="https://github.com/quarkiverse/quarkus-operator-sdk"&gt;JOSDK Quarkus extension &lt;code&gt;quarkus-operator-sdk&lt;/code&gt;&lt;/a&gt;, also called QOSDK, facilitates the development experience by taking care of managing the Custom Resource Definition automatically. The &lt;a href="https://developers.redhat.com/articles/2022/04/04/writing-kubernetes-operators-java-josdk-part-3-implementing-controller"&gt;third article&lt;/a&gt; focused on requirements for implementing the reconciliation logic for the example operator you build in this series. Many things have changed since the third installment of this series. This article will thus focus on updating the code to the latest versions and provide upgrading strategies.&lt;/p&gt; &lt;h2&gt;Where things stand&lt;/h2&gt; &lt;p&gt;You implemented a simple operator exposing your application outside the cluster via an &lt;code&gt;Ingress&lt;/code&gt;, creating the associated &lt;code&gt;Deployment&lt;/code&gt; and &lt;code&gt;Service&lt;/code&gt; along the way. However, it has been a while since the last part of this blog series and many things have changed. When the third article was written, QOSDK was in version 3.0.4. Now it is up to 6.3.0. Quarkus has also been updated. How can you update your operator to use more recent versions, and what are possible strategies to update your code?&lt;/p&gt; &lt;h2&gt;How to use Quarkus update&lt;/h2&gt; &lt;p&gt;Upgrading a project is always a tricky proposition, especially when there is a wide gap between the old and new versions. Quarkus can help you with this task, though it might not work in all cases. In this case, you want to migrate from Quarkus 2.7.3.Final to the latest version, which at the time of writing this article, is 3.2.4.Final. You can use the &lt;code&gt;update&lt;/code&gt; command that Quarkus provides. If you have the &lt;code&gt;quarkus&lt;/code&gt; command line tool, you might want to upgrade it first and then simply run &lt;code&gt;quarkus update&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Otherwise, using maven only, you can run:&lt;/p&gt; &lt;pre class="CodeRay highlight"&gt; &lt;code data-lang="shell"&gt;mvn io.quarkus.platform:quarkus-maven-plugin:3.2.4.Final:update -N&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The complete procedure is detailed in the &lt;a href="https://quarkus.io/guides/update-quarkus"&gt;related Quarkus guide&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In your case, you should notice that the update procedure fails with an error when the command attempts to check the updated project as follows:&lt;/p&gt; &lt;pre class="CodeRay highlight"&gt; &lt;code data-lang="shell"&gt;[INFO] [ERROR] [ERROR] Some problems were encountered while processing the POMs: [INFO] [ERROR] 'dependencies.dependency.version' for io.quarkiverse.operatorsdk:quarkus-operator-sdk-csv-generator:jar is missing. @ line 38, column 17&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Updating outdated QOSDK dependency&lt;/h2&gt; &lt;p&gt;The problem occurs because this dependency doesn’t exist anymore. Though the project actually doesn’t need this dependency at this point, it is included by default when bootstrapping a QOSDK project using the &lt;code&gt;operator-sdk&lt;/code&gt; CLI and allows for automatic generation of &lt;a href="https://olm.operatorframework.io/"&gt;Operator Lifecycle Manager (OLM)&lt;/a&gt; bundles. OLM enables you to manage the lifecycle of operators on clusters in a more principled way. We might discuss this feature in greater detail in a future article.&lt;/p&gt; &lt;p&gt;There are two ways to fix your project. If you’re not interested in the feature, you can remove the dependency, or change it to the correct one. This dependency doesn’t exist in its previous form anymore because it has been renamed to better reflect its expanded scope. It initially focused solely on the &lt;a href="https://olm.operatorframework.io/docs/concepts/crds/clusterserviceversion/"&gt;&lt;code&gt;ClusterServiceVersion&lt;/code&gt;&lt;/a&gt; part of OLM bundles, but now extends to generating complete bundles. The feature was actually disabled using &lt;code&gt;quarkus.operator-sdk.generate-csv=false&lt;/code&gt; in the &lt;code&gt;application.properties&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;The new dependency name is &lt;code&gt;quarkus-operator-sdk-bundle-generator&lt;/code&gt;. So use that if you want to use the OLM generation feature. Note that you will also need to change the associated property name to activate the feature. You’ll see a warning in the logs that the property doesn’t exist if you don’t, and the OLM generation will be activated by default. The new property is named &lt;code&gt;quarkus.operator-sdk.bundle.enabled&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;After making these changes, you can re-run the update command. It should now succeed, with an output similar to the following:&lt;/p&gt; &lt;pre class="CodeRay highlight"&gt; &lt;code data-lang="shell"&gt;[INFO] Detected project Java version: 11 [INFO] Quarkus platform BOMs: [INFO] io.quarkus:quarkus-bom:pom:3.2.4.Final ✔ [INFO] Add: io.quarkus.platform:quarkus-operator-sdk-bom:pom:3.2.4.Final [INFO] [INFO] Extensions from io.quarkus:quarkus-bom: [INFO] io.quarkus:quarkus-micrometer-registry-prometheus ✔ [INFO] [INFO] Extensions from io.quarkus.platform:quarkus-operator-sdk-bom: [INFO] Update: io.quarkiverse.operatorsdk:quarkus-operator-sdk-bundle-generator:6.3.0 -&gt; remove version (managed) [INFO] Update: io.quarkiverse.operatorsdk:quarkus-operator-sdk:6.3.0 -&gt; remove version (managed)&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Strategies for QOSDK and Quarkus updates&lt;/h2&gt; &lt;p&gt;Now you can see that you can actually simplify things even further. It is advising you to add the &lt;code&gt;io. quarkus.platform:quarkus-operator-sdk-bom:pom:3.2.4.Final&lt;/code&gt; dependency. Indeed, QOSDK has been added to the Quarkus platform, making it easier to consume from a given Quarkus version. Switching to this BOM only allows you to decide which version of Quarkus to use, and the BOM will make sure you get the appropriate QOSDK version.&lt;/p&gt; &lt;pre class="CodeRay highlight"&gt; &lt;code data-lang="xml"&gt;&lt;strong&gt;&lt;dependencyManagement&gt;&lt;/strong&gt; &lt;strong&gt;&lt;dependencies&gt;&lt;/strong&gt; &lt;strong&gt;&lt;dependency&gt;&lt;/strong&gt; &lt;strong&gt;&lt;groupId&gt;&lt;/strong&gt;io.quarkiverse.operatorsdk&lt;strong&gt;&lt;/groupId&gt;&lt;/strong&gt; &lt;strong&gt;&lt;artifactId&gt;&lt;/strong&gt;quarkus-operator-sdk-bom&lt;strong&gt;&lt;/artifactId&gt;&lt;/strong&gt; &lt;strong&gt;&lt;version&gt;&lt;/strong&gt;${quarkus-sdk.version}&lt;strong&gt;&lt;/version&gt;&lt;/strong&gt; &lt;strong&gt;&lt;scope&gt;&lt;/strong&gt;import&lt;strong&gt;&lt;/scope&gt;&lt;/strong&gt; &lt;strong&gt;&lt;type&gt;&lt;/strong&gt;pom&lt;strong&gt;&lt;/type&gt;&lt;/strong&gt; &lt;strong&gt;&lt;/dependency&gt;&lt;/strong&gt; &lt;strong&gt;&lt;/dependencies&gt;&lt;/strong&gt; &lt;strong&gt;&lt;/dependencyManagement&gt;&lt;/strong&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This project is currently using the QOSDK BOM with &lt;code&gt;quarkus-sdk.version&lt;/code&gt; with the 3.0.4 value. You’ll also note that there is a &lt;code&gt;quarkus.version&lt;/code&gt; property with the 2.7.3.Final value. Looking at the QOSDK BOM, you can see that there is also a Quarkus version property defined there, with the same &lt;code&gt;quarkus.version&lt;/code&gt; name. Therefore, if you upgrade the QOSDK version, with the current setup, you need to make sure to also upgrade the Quarkus version in your project in such a way that is compatible with the version defined in the QOSDK BOM.&lt;/p&gt; &lt;p&gt;Using the QOSDK BOM defined by the Quarkus platform (i.e., Using the &lt;code&gt;io.quarkus.platform:quarkus-operator-sdk-bom&lt;/code&gt; artifact instead of the &lt;code&gt;io.quarkiverse.operatorsdk:quarkus-operator-sdk-bom&lt;/code&gt;, note the different group identifier.) simplifies this aspect by making sure that both QOSDK and Quarkus versions are aligned. The downside of this is that using the QOSDK BOM directly from the QOSDK project, you have the Quarkus BOM automatically included in your project. The price for this, as previously explained, is that you need to make sure the versions are in sync.&lt;/p&gt; &lt;p&gt;That said, you can also see that it is letting us know that there is a more recent version of the QOSDK extension (6. 3.0), which will only be available from the Quarkus platform starting with version 3.2.5.Final. Using the Quarkus platform, therefore, means that you’re not necessarily using the latest QOSDK version. This is, however, the version that is verified to work with the platform as a whole, so this is the more conservative option.&lt;/p&gt; &lt;p&gt;If you wish to use the absolute latest version of QOSDK, you should use the BOM provided by QOSDK, but you will need to make sure to update the Quarkus version using the &lt;code&gt;quarkus.version&lt;/code&gt;, while updating the QOSDK version using the &lt;code&gt;quarkus-sdk.version&lt;/code&gt; property in your &lt;code&gt;pom.xml&lt;/code&gt; file as previously done.&lt;/p&gt; &lt;p&gt;Which approach to choose depends on your appetence for risk, or how you wish to manage your dependencies. Generally speaking, the Quarkus platform is updated frequently, and QOSDK versions are usually updated accordingly as needed. So the Quarkus platform is usually up-to-date when it comes to the latest QOSDK version. If you absolutely need the latest QOSDK version, upgrading from the Quarkus platform offerings, a patch or even a minor version should typically work with issues since QOSDK strives to maintain backwards compatibility between minor versions.&lt;/p&gt; &lt;p&gt;Going the opposite direction, upgrading Quarkus to a minor version above (e.g., from 3.2.x to 3.3.x) might prove tricky since the Fabric8 Kubernetes client version used by that new Quarkus version might also have been updated to a new minor version. This has been known to bring API changes, so you might want to tread carefully with such updates.&lt;/p&gt; &lt;p&gt;Actually, QOSDK issues debug-level warnings when it detects version mismatches (minor version and above, patch level mismatches considered safe) between Quarkus, JOSDK, and Fabric8 Kubernetes client. You can even configure it to fail a build by setting the &lt;code&gt;quarkus.operator-sdk.fail-on-version-check&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;. Please refer to the &lt;a href="https://docs.quarkiverse.io/quarkus-operator-sdk/dev/index.html#quarkus-operator-sdk_quarkus.operator-sdk.fail-on-version-check"&gt;documentation&lt;/a&gt; for more details.&lt;/p&gt; &lt;p&gt;It’s also worth repeating that since QOSDK bundles JOSDK, you do not need to worry about updating that dependency separately. One less thing to worry about.&lt;/p&gt; &lt;h2&gt;Adapting to Fabric8 Kubernetes client changes&lt;/h2&gt; &lt;p&gt;Now that the dependencies are sorted out, if you try to build now, you should get a compilation error due to an API change in the Fabric8 Kubernetes client:&lt;/p&gt; &lt;pre class="CodeRay highlight"&gt; &lt;code data-lang="java"&gt;[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.8.1:compile (&lt;strong&gt;default&lt;/strong&gt;-compile) on project expose: Compilation failure [ERROR] exposedapp-rhdblog/src/main/java/io/halkyon/ExposedAppReconciler.java:[63,33] cannot find symbol [ERROR] symbol: method withIntVal(&lt;strong&gt;int&lt;/strong&gt;) [ERROR] location: &lt;strong&gt;interface&lt;/strong&gt; &lt;strong&gt;io&lt;/strong&gt;.fabric8.kubernetes.api.model.ServicePortFluent.TargetPortNested&lt;io.fabric8.kubernetes.api.model.ServiceSpecFluent.PortsNested&lt;io.fabric8.kubernetes.api.model.ServiceFluent.SpecNested&lt;io.fabric8.kubernetes.api.model.ServiceBuilder&gt;&gt;&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This issue is easily fixed by changing the following line:&lt;/p&gt; &lt;pre class="CodeRay highlight"&gt; &lt;code data-lang="java"&gt;.withNewTargetPort().withIntVal(8080).endTargetPort()&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;to:&lt;/p&gt; &lt;pre class="CodeRay highlight"&gt; &lt;code data-lang="java"&gt;.withNewTargetPort(8080)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The Fabric8 Kubernetes client provides detailed notes for each release. It’s always a good idea to take a look at them, especially whenever a new minor version is released (&lt;a href="https://github.com/fabric8io/kubernetes-client/releases/tag/v6.8.0"&gt;here&lt;/a&gt; are the notes for the 6.8. 0 release, which does contain breaking changes). Another interesting resource is the &lt;a href="https://github.com/fabric8io/kubernetes-client/blob/main/doc/CHEATSHEET.md"&gt;cheat sheet&lt;/a&gt;, which contains a wealth of information on how to perform a wide variety of tasks using the client.&lt;/p&gt; &lt;p&gt;That said, you should now be all set for this batch of updates!&lt;/p&gt; &lt;h2 id="_conclusion"&gt;Summary&lt;/h2&gt; &lt;p&gt;While less focused on writing operators per se, this article still covered an important part of any software development: upgrading dependencies. Your operator should be now ready for improvements, which we will tackle in the next article. We will also discuss adding status handling and how to make your operator react to events that are not targeting primary resources.&lt;/p&gt; &lt;p&gt;For reference, you can find the completed code for this part under the &lt;a href="https://github.com/halkyonio/exposedapp-rhdblog/tree/part-4"&gt;&lt;code&gt;part-4&lt;/code&gt; tag&lt;/a&gt; of the &lt;a href="https://github.com/halkyonio/exposedapp-rhdblog"&gt;https://github.com/halkyonio/exposedapp-rhdblog&lt;/a&gt; repository.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/09/19/write-operators-java-josdk-part-4-upgrading-strategies" title="Write operators in Java with JOSDK, Part 4: Upgrading strategies"&gt;Write operators in Java with JOSDK, Part 4: Upgrading strategies&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Christophe Laprun</dc:creator><dc:date>2023-09-19T07:00:00Z</dc:date></entry><entry><title>When Quarkus meets Virtual Threads</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/virtual-thread-1/&#xA;            " /><author><name>Clement Escoffier (https://twitter.com/clementplop)</name></author><id>https://quarkus.io/blog/virtual-thread-1/</id><updated>2023-09-19T00:00:00Z</updated><published>2023-09-19T00:00:00Z</published><summary type="html">Java 21 offers a new feature that will reshape the development of concurrent applications in Java. For over two years, the Quarkus team explored integrating this new feature to ease the development of distributed applications, including microservices and event-driven applications. This blog post is the first part of a series...</summary><dc:creator>Clement Escoffier (https://twitter.com/clementplop)</dc:creator><dc:date>2023-09-19T00:00:00Z</dc:date></entry><entry><title>A statistics update in Open vSwitch user space datapath</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/09/18/statistics-update-open-vswitch-user-space-datapath" /><author><name>David Marchand</name></author><id>31406c88-48e4-4cec-a6b6-9095aa82356d</id><updated>2023-09-18T07:00:00Z</updated><published>2023-09-18T07:00:00Z</published><summary type="html">&lt;p&gt;With the demands for higher bandwidth, came the need for scaling and processing packets on more CPU resources. In Open vSwitch (OVS) using DPDK for faster IO, this translated to using more receive and transmit queues to allow more PMD threads to process the packets. This adds some complexity to a system not easy to understand in the first place. Support or operation people still want to know how much traffic is received and how it is distributed across the CPU resources. To offer help, this article describes new statistics added for the user space datapath in OVS 2.17 and later.&lt;/p&gt; &lt;h2&gt;Per queue statistics for DPDK ports&lt;/h2&gt; &lt;p&gt;A first evolution in OVS 2.17 consisted of &lt;a href="https://github.com/openvswitch/ovs/commit/1140c87e2eb7"&gt;exposing receive and transmit queues statistics&lt;/a&gt; per DPDK physical ports in ovsdb.&lt;/p&gt; &lt;p&gt;For example:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# ovs-vsctl get interface dpdk0 statistics | sed -e 's#[{}]##g' -e 's#, #\n#g' | grep packets= | grep -v '=0$' rx_packets=5553474 rx_q0_packets=3705290 rx_q1_packets=1848184 tx_broadcast_packets=220 tx_multicast_packets=488 tx_packets=39406658924 tx_q1_packets=3700644 tx_q2_packets=97 tx_q3_packets=19696490438 tx_q4_packets=19706467745&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Those per queue statistics require support from the DPDK driver backing the port.&lt;/p&gt; &lt;p&gt;A vast majority of physical (and even some virtual) NIC DPDK drivers do support those statistics. But if no statistics appear in ovsdb, you may check for support by looking for the RTE_ETH_DEV_AUTOFILL_QUEUE_XSTATS (1 &lt;&lt; 6) value in the port dev_flags bitmask through the DPDK telemetry tool (coming with the dpdk-tools rpm).&lt;/p&gt; &lt;p&gt;For example, check port 0:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# if [ $(($(echo /ethdev/info,0 | dpdk-telemetry.py -f /var/run/openvswitch/dpdk/rte | jq -r '.["/ethdev/info"]["dev_flags"]') &amp; 64)) != 0 ]; then echo per queue stats are supported; else echo per queue stats may not be implemented for this driver; fi per queue stats are supported&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Per queue statistics for vhost-user ports&lt;/h2&gt; &lt;p&gt;Getting the same level of information for vhost-user ports has required some reworking in the DPDK vhost-user libary because the library was not accounting such information.&lt;/p&gt; &lt;p&gt;&lt;br /&gt; This was enhanced by the community in the DPDK v22.07 release with this &lt;a href="https://git.dpdk.org/dpdk/commit/?id=be75dc99ea1f"&gt;change&lt;/a&gt;, and its support was merged in OVS with this &lt;a href="https://github.com/openvswitch/ovs/commit/3b29286db1c5"&gt;change&lt;/a&gt; in the 3.1 version:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# ovs-vsctl get interface vhost0 statistics | sed -e 's#[{}]##g' -e 's#, #\n#g' | grep packets= | grep -v '=0$' rx_65_to_127_packets=2987595 rx_packets=2987595 rx_q0_good_packets=2987595 rx_q0_size_65_127_packets=2987595 tx_65_to_127_packets=14075727 tx_packets=14075727 tx_q0_good_packets=14075727 tx_q0_size_65_127_packets=14075727&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;More vhost-user statistics&lt;/h2&gt; &lt;p&gt;As a bonus of the work exposing per queue statistics, the vhost-user library started exposing other internal counters.&lt;/p&gt; &lt;p&gt;The virtio driver (e.g., the Linux kernel driver by default) plugged on a vhost-user port may require guest notifications for signaling packets delivery. Triggering those notifications impacts the processing cost of such packets, which is why keeping track of the amount of notifications is of interest.&lt;/p&gt; &lt;p&gt;Previously, OVS was exposing a coverage counter for those notifications, and until OVS 3.0, you could use the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# ovs-appctl coverage/show | grep vhost_notification vhost_notification 0.0/sec 0.000/sec 2.0283/sec total: 7302&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This coverage counter was only hinting at some vhost-user ports used by an unidentified virtual machine.&lt;/p&gt; &lt;p&gt;Starting OVS 3.1, the coverage counter has been removed in favor of per queue and per port statistics (&lt;a href="https://git.dpdk.org/dpdk/commit/?id=1ea74efd7fa4"&gt;DPDK change&lt;/a&gt; / &lt;a href="https://github.com/openvswitch/ovs/commit/c9e10ac57fb8"&gt;OVS change&lt;/a&gt;):&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# ovs-vsctl get interface vhost0 statistics | sed -e 's#[{}]##g' -e 's#, #\n#g' | grep guest_notifications rx_q0_guest_notifications=12 rx_q1_guest_notifications=1 tx_q0_guest_notifications=3 tx_q1_guest_notifications=2&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This nice addition makes it possible to directly point at which virtual machine is slowing down packet processing. Other vhost-user statistics have been added, like exposing the &lt;a href="https://git.dpdk.org/dpdk/commit/?id=7247b7464ef9"&gt;vhost-user IOTLB cache internals&lt;/a&gt;. More may be added in the future as members of the community express new requirements.&lt;/p&gt; &lt;h2&gt;A final note about statistics&lt;/h2&gt; &lt;p&gt;As OVS stores per interface statistics in its ovsdb, choices were made to select generic (iow not driver specific) statistics, and that helps in a majority of use cases.&lt;/p&gt; &lt;p&gt;However, if you do not find the driver-specific statistics you're looking for, it is still possible for debugging to use the DPDK telemetry tool and retrieve all unfiltered port statistics as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# echo /ethdev/xstats,0 | dpdk-telemetry.py -f /var/run/openvswitch/dpdk/rte { "/ethdev/xstats": { "rx_good_packets": 5553474, "tx_good_packets": 39406658860, "rx_good_bytes": 710844672, "tx_good_bytes": 4886425719104, "rx_missed_errors": 78892319, "rx_errors": 0, "tx_errors": 0, "rx_mbuf_allocation_errors": 0, "rx_q0_packets": 3705290, "rx_q0_bytes": 474277120, "rx_q0_errors": 0, "rx_q1_packets": 1848184, "rx_q1_bytes": 236567552, "rx_q1_errors": 0, "tx_q0_packets": 0, "tx_q0_bytes": 0, "tx_q1_packets": 3700615, "tx_q1_bytes": 458874621, "tx_q2_packets": 71, "tx_q2_bytes": 8120, "tx_q3_packets": 19696490435, "tx_q3_bytes": 2442364825811, "tx_q4_packets": 19706467739, "tx_q4_bytes": 2443602010552, "rx_wqe_errors": 0, "rx_unicast_packets": 84445793, "rx_unicast_bytes": 10471278332, "tx_unicast_packets": 39406658216, "tx_unicast_bytes": 4886425618784, "rx_multicast_packets": 0, "rx_multicast_bytes": 0, "tx_multicast_packets": 444, "tx_multicast_bytes": 35320, "rx_broadcast_packets": 0, "rx_broadcast_bytes": 0, "tx_broadcast_packets": 200, "tx_broadcast_bytes": 65000, "tx_phy_packets": 39406658860, "rx_phy_packets": 84445793, "rx_phy_crc_errors": 0, "tx_phy_bytes": 5044052354544, "rx_phy_bytes": 10809061504, "rx_phy_in_range_len_errors": 0, "rx_phy_symbol_errors": 0, "rx_phy_discard_packets": 0, "tx_phy_discard_packets": 0, "tx_phy_errors": 0, "rx_out_of_buffer": 78892319, "tx_pp_missed_interrupt_errors": 0, "tx_pp_rearm_queue_errors": 0, "tx_pp_clock_queue_errors": 0, "tx_pp_timestamp_past_errors": 0, "tx_pp_timestamp_future_errors": 0, "tx_pp_jitter": 0, "tx_pp_wander": 0, "tx_pp_sync_lost": 0 } }&lt;/code&gt;&lt;/pre&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/09/18/statistics-update-open-vswitch-user-space-datapath" title="A statistics update in Open vSwitch user space datapath"&gt;A statistics update in Open vSwitch user space datapath&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>David Marchand</dc:creator><dc:date>2023-09-18T07:00:00Z</dc:date></entry><entry><title>Quarkus Newsletter #36 - September</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-newsletter-36/&#xA;            " /><author><name>James Cobb (https://twitter.com/insectengine)</name></author><id>https://quarkus.io/blog/quarkus-newsletter-36/</id><updated>2023-09-15T00:00:00Z</updated><published>2023-09-15T00:00:00Z</published><summary type="html">Explore how we can use the Testcontainers Desktop app while building a Quarkus application by reading "Joyful Quarkus Application Development using Testcontainers Desktop" by Siva Katamreddy. Extensions can significantly increase the application’s performance, help developers be more productive while developing their applications, integrate complex dependencies much easier, and simplify the...</summary><dc:creator>James Cobb (https://twitter.com/insectengine)</dc:creator><dc:date>2023-09-15T00:00:00Z</dc:date></entry><entry><title>How to configure RHEL as a workstation during installation</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/09/14/how-configure-rhel-workstation-during-installation" /><author><name>Nikhil Mungale</name></author><id>a410ee41-5f4f-455e-91fe-5183739593cf</id><updated>2023-09-14T07:00:00Z</updated><published>2023-09-14T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) is a powerful and widely-used &lt;a href="https://developers.redhat.com/topics/linux/"&gt;Linux&lt;/a&gt; distribution known for its stability, security features, and enterprise-grade support. When installing RHEL, you have the opportunity to configure it as a workstation to optimize performance and usability for your specific needs. In this article, we will guide you through the steps to configure RHEL as a workstation during the installation process.&lt;/p&gt; &lt;h2&gt;What is RHEL workstation?&lt;/h2&gt; &lt;p&gt;The organization needs high-end workstations that can support developers and power users, such as artists, physicians, scientists, and engineers, so they can concentrate on what they do best. Designed for advanced Linux users and day-to-day usage with powerful hardware, &lt;a href="https://www.redhat.com/en/store/red-hat-enterprise-linux-workstation"&gt;Red Hat Enterprise Linux for Workstations&lt;/a&gt; (RHEL Workstation) is optimized for high-performance graphics, animation, and scientific applications. It includes all the capabilities and applications that workstation users need, plus development tools for provisioning and administration.&lt;/p&gt; &lt;h2&gt;How to install and configure a RHEL workstation&lt;/h2&gt; &lt;p&gt;The following sections will demonstrate how to configure RHEL as a workstation during the installation process.&lt;/p&gt; &lt;h3&gt;Prerequisites&lt;/h3&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Red Hat Enterprise Linux installation media or ISO file.&lt;/li&gt; &lt;li aria-level="1"&gt;Bootable USB/DVD drive containing.ISO file of RHEL 9.2.&lt;/li&gt; &lt;li aria-level="1"&gt;Activated no-cost &lt;a href="developer.redhat.com"&gt;Red Hat Developer subscription&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;A system that meets the following requirements: &lt;ul&gt;&lt;li aria-level="2"&gt;A 64-bit x86 or ARM machine&lt;/li&gt; &lt;li aria-level="2"&gt;4 GB of RAM&lt;/li&gt; &lt;li aria-level="2"&gt;At least 20 GB of available disk space(50 GB for best results)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Prepare Windows system for RHEL installation&lt;/h3&gt; &lt;p&gt;We are making a single machine with two operating systems, RHEL workstation and Windows 11. We need to isolate the operating systems from each other to install RHEL on the same disk where Windows OS is already installed.&lt;/p&gt; &lt;p&gt;Follow these steps required to make a single disk into multiple partitions:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Right-click on the Windows icon and select the disk management option, as shown in Figure 1.&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture1_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture1_0.png?itok=N9SnoOfv" width="596" height="497" alt="Disk management" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1:  Selecting Disk Management.&lt;/figcaption&gt;&lt;/figure&gt;&lt;ol start="2"&gt;&lt;li aria-level="1"&gt;You will see the window with all drives shown graphically.&lt;/li&gt; &lt;li aria-level="1"&gt;Select the drive which has enough space to make a partition.&lt;/li&gt; &lt;li aria-level="1"&gt;Right-click on drive and select the &lt;strong&gt;Shrink Volume&lt;/strong&gt; option.&lt;/li&gt; &lt;li aria-level="1"&gt;In the wizard, define the partition and size by entering &lt;strong&gt;Enter the amount of shrink in MB&lt;/strong&gt; and click on the &lt;strong&gt;Shrink&lt;/strong&gt; button. (Note: Define space at least 50GB for best experience.)&lt;/li&gt; &lt;li aria-level="1"&gt;The freed space should now be shown with &lt;strong&gt;Unallocated Status&lt;/strong&gt; in the bottom pane. Right-click on it and select &lt;strong&gt;New Simple Volume&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;In the next wizard, select &lt;strong&gt;Do not assign a drive letter or drive path &lt;/strong&gt;and click on &lt;strong&gt;Next&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;In the &lt;strong&gt;Format Partition&lt;/strong&gt; window, keep everything as default and change the&lt;strong&gt; Volume label&lt;/strong&gt; new volume to &lt;strong&gt;RHEL.&lt;/strong&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Click &lt;strong&gt;Finish&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;After completing the setup, you will see the disk partition for RHEL in Figure 2.&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture2_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture2_0.png?itok=-Hbehbyh" width="600" height="257" alt="disk" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Disk partition for RHEL OS&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Start installing RHEL&lt;/h3&gt; &lt;p&gt;To begin installation on RHEL, make sure a bootable USB/DVD is attached to the device.&lt;/p&gt; &lt;p&gt;Press the shift&lt;strong&gt; &lt;/strong&gt;key and restart&lt;strong&gt; &lt;/strong&gt;the system, as shown in Figure 3.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture3_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture3_0.png?itok=VGosab6M" width="493" height="436" alt="restart" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: Restart the system&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;During system boot up, the screen in Figure 4 appears. Click on the&lt;strong&gt; Use a device &lt;/strong&gt;option.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture4_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture4_0.png?itok=02Yixx_C" width="600" height="370" alt="boot option" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4:  Choosing a boot option.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Select the&lt;strong&gt; Linpus lite (USB&lt;/strong&gt;) option using navigation keys from the keyboard and press enter, as shown in Figure 5.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture5_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture5_0.png?itok=pGca53f4" width="600" height="405" alt="USB" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 5: Select the USB boot device&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The screen in Figure 6 appears to choose the RHEL installation option, and boot the system using bootable installation media containing the RHEL 9.iso file. For this article, we will use &lt;strong&gt;Red Hat Enterprise Linux 9.2.&lt;/strong&gt; Then press enter.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture6_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture6_0.png?itok=4v1Vvns4" width="600" height="453" alt="rhel select" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 6: Select RHEL to install.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: During booting, you can skip the media checking step by hitting the &lt;strong&gt;Esc&lt;/strong&gt; key.&lt;/p&gt; &lt;p&gt;As shown in Figure 7, select the language of RHEL to install and click &lt;strong&gt;Continue&lt;/strong&gt;.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture7_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture7_0.png?itok=e1blA1Zw" width="600" height="449" alt="language select" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 7: Selecting the OS language.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Configure RHEL&lt;/h3&gt; &lt;p&gt;During installation, we must manually configure RHEL.&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Click on &lt;strong&gt;Connect to Red Hat&lt;/strong&gt;, as shown in Figure 8.&lt;/li&gt; &lt;li aria-level="1"&gt;Fill in your username&lt;strong&gt; &lt;/strong&gt;and password&lt;strong&gt; &lt;/strong&gt;for the activated no-cost Red Hat Developer subscription.&lt;/li&gt; &lt;li aria-level="1"&gt;Leave the organization blank (optional).&lt;/li&gt; &lt;li aria-level="1"&gt;Click on the &lt;strong&gt;Register &lt;/strong&gt;button.&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture8.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture8.png?itok=Df1CXQvA" width="600" height="426" alt="config select" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 8: The RHEL configuration screen. &lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Choose the disk and partition&lt;/h3&gt; &lt;p&gt;The &lt;strong&gt;Installation Destination&lt;/strong&gt; has a caution sign. To install RHEL, we must select the drive. There are two ways to install RHEL on disk with a dedicated disk and partitioned disk space.&lt;/p&gt; &lt;h4&gt;Dedicated disk&lt;/h4&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Click on &lt;strong&gt;Installation Destination&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;It shows all available disks. Select the disk on which you want to install RHEL.&lt;/li&gt; &lt;li aria-level="1"&gt;Click &lt;strong&gt;Done&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;h4&gt;Partitioned disk&lt;/h4&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Get into the &lt;strong&gt;Installation Destination&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Click on disk and select the claim drive.&lt;/li&gt; &lt;li aria-level="1"&gt;In the window in Figure 9, you will see all the partitions of the hard disk.&lt;/li&gt; &lt;li aria-level="1"&gt;Select &lt;strong&gt;RHEL&lt;/strong&gt; labeled drive.&lt;/li&gt; &lt;li aria-level="1"&gt;Click on &lt;strong&gt;Delete &lt;/strong&gt;to the left.&lt;/li&gt; &lt;li aria-level="1"&gt;Select the &lt;strong&gt;Reclaim space&lt;/strong&gt; button.&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture9.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture9.png?itok=vdhsbR1r" width="600" height="450" alt="disk select" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 9: Choose the disk for OS installation.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Configure the network and host name&lt;/h3&gt; &lt;p&gt;Next, configure the system network.&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Click on the &lt;strong&gt;Network &amp; HostName&lt;/strong&gt; under &lt;strong&gt;SYSTEM&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Turn on the adaptor by clicking the toggle switch.&lt;/li&gt; &lt;li aria-level="1"&gt;If you have built-in WIFI in the system, it shows the Ethernets below as a secondary option to connect to the internet.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you do not enable the network here, you will not be able to install RHEL, because it downloads all dependencies over the internet during the installation process.&lt;/p&gt; &lt;h3&gt;Set the root password&lt;/h3&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Scroll down to the &lt;strong&gt;Root Password&lt;/strong&gt; under the user setting and click on it.&lt;/li&gt; &lt;li aria-level="1"&gt;Next, add the password two times. Make sure it is a strong password. Based on the complexity of your password, it will show the strength of the password under it.&lt;/li&gt; &lt;/ol&gt;&lt;h3&gt;Select the software&lt;/h3&gt; &lt;p&gt;RHEL gives the flexibility to install additional packages and tools during the installation process so users can get most of the things in a single go. Refer to Figure 10 for the following steps:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Click on the &lt;strong&gt;Software Selection&lt;/strong&gt; button.&lt;/li&gt; &lt;li aria-level="1"&gt;Select the &lt;strong&gt;Workstation &lt;/strong&gt;under the &lt;strong&gt;Base Environment&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;From &lt;strong&gt;Additional software for Selected Environment,&lt;/strong&gt; select the tools of your preference, such as container management, security tools, etc.&lt;/li&gt; &lt;li aria-level="1"&gt;Click &lt;strong&gt;Done&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture10.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture10.png?itok=WCJRDTIL" width="600" height="458" alt="select workstation" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 10: Selecting workstation as the RHEL version. &lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Install the RHEL Workstation&lt;/h3&gt; &lt;p&gt;After completing all configurations, we are ready to begin the installation of RHEL Workstation.&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Click the &lt;strong&gt;Begin installation&lt;/strong&gt; button shown in Figure 11 to start the installation.&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture11.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture11.png?itok=2h5gV_Nt" width="600" height="450" alt="all config done" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 11:  Begin the installation.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The installation may take some time based on your internet speed and compute power.&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;After installation, we need to reboot the system, by clicking on the &lt;strong&gt;Reboot System&lt;/strong&gt; button in Figure 12.&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture12.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture12.png?itok=Vv5vSrrd" width="600" height="443" alt="installation done" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 12: Rebooting the system.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Set up RHEL&lt;/h3&gt; &lt;p&gt;After the successful installation of RHEL, you will see the screen in Figure 13.&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Simply click &lt;strong&gt;Start Setup&lt;/strong&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture13.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture13.png?itok=HwquSu0y" width="600" height="456" alt="rhel setup" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 13:  Start the RHEL setup.&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li aria-level="1"&gt;RHEL requires more inputs before using it.&lt;/li&gt; &lt;li aria-level="1"&gt;Accept the policy of RHEL and click on next.&lt;/li&gt; &lt;li aria-level="1"&gt;Add the accounts of Google and Microsoft or skip it and click on Next.&lt;/li&gt; &lt;li aria-level="1"&gt;Create a new user ID (Figure 14). Fill in the &lt;strong&gt;Full Name&lt;/strong&gt; and &lt;strong&gt;Username &lt;/strong&gt;boxes and click &lt;strong&gt;Next&lt;/strong&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture14.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture14.png?itok=tQPQ7HZ9" width="600" height="445" alt="Create a user" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 14: Create a user.&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li aria-level="1"&gt;On the next screen, set the password for the login system. Make sure the password is strong.&lt;/li&gt; &lt;li aria-level="1"&gt;Click on the &lt;strong&gt;Start Using Red Hat Enterprise Linux&lt;/strong&gt; (Figure 15).&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture15.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture15.png?itok=Cf5G3uA8" width="600" height="450" alt="click on start" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 15: Click the Start Using Red Hat Enterprise Linux button.&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;/ul&gt;&lt;p&gt;RHEL Workstation is now ready for personal and high-end use (Figure 16).&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/picture16.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/picture16.png?itok=GB0cpuQS" width="600" height="449" alt="workstation done" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 16: The desktop view of RHEL 9.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Find more resources&lt;/h2&gt; &lt;p&gt;If you want to have a more hands-on experience of RHEL, you can follow the &lt;a href="https://www.redhat.com/en/interactive-labs/enterprise-linux"&gt;Red Hat curated lab&lt;/a&gt;. Learn more with Red Hat's hands-on labs for all skill levels. Try these labs to see your favorite products in action.&lt;/p&gt; &lt;p&gt;You can also &lt;a href="https://developers.redhat.com/products/rhel/download"&gt;get customized RHEL images&lt;/a&gt; for AWS, Google Cloud Platform, Microsoft Azure, and VMware and deploy them to the platform of your choice.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/09/14/how-configure-rhel-workstation-during-installation" title="How to configure RHEL as a workstation during installation"&gt;How to configure RHEL as a workstation during installation&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Nikhil Mungale</dc:creator><dc:date>2023-09-14T07:00:00Z</dc:date></entry><entry><title>Quarkus security releases for CVE-2023-4853</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/cve-2023-4853/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/cve-2023-4853/</id><updated>2023-09-14T00:00:00Z</updated><published>2023-09-14T00:00:00Z</published><summary type="html">We have just released updates to Quarkus 2.16.11.Final, 3.2.6.Final, and 3.3.3 and Red Hat build of Quarkus 2.13.18.SP2 that fix the issue reported in CVE-2023-4853. This issue affects anyone using HTTP security path-based rules to protect HTTP endpoints. Recommendations If you are using any older versions of Quarkus (ranging from...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2023-09-14T00:00:00Z</dc:date></entry><entry><title>Introducing Ansible Molecule with Ansible Automation Platform</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/09/13/introducing-ansible-molecule-ansible-automation-platform" /><author><name>Anshul Behl</name></author><id>dd391abe-15a5-43e1-9cfd-d6b0b32bf624</id><updated>2023-09-13T07:00:00Z</updated><published>2023-09-13T07:00:00Z</published><summary type="html">&lt;p&gt;Ansible Molecule is a tool designed to aid in developing and testing Ansible playbooks, roles, and collections. It provides support for functional testing of Ansible content across multiple instances, operating systems and distributions, virtualization providers, test frameworks, and testing scenarios. Molecule helps Ansible content creators (&lt;a href="https://developers.redhat.com/topics/automation"&gt;automation&lt;/a&gt; specialists) consistently deliver automation content that is scalable, repeatable, and compatible with the latest Ansible versions.&lt;/p&gt; &lt;p&gt;Ansible Molecule 6 is now available as a &lt;a href="https://access.redhat.com/support/offerings/devpreview"&gt;developer preview&lt;/a&gt; with &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Red Hat Ansible Automation Platform&lt;/a&gt;. This version will refocus and redefine the project as a tool for testing Ansible content with Ansible Automation Platform.&lt;/p&gt; &lt;p&gt;The developer preview enables us to collect feedback from our users as we work towards making it an integral and supported part of the Ansible Automation Platform developer experience. This release is part of our broader strategy to reduce the learning curve required for IT professionals and Ansible specialists with little to no coding skills to build, test, and deploy their automation content.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note to current Molecule users:&lt;/strong&gt; If you are already familiar with the Molecule project and are using it to test your automation content, there might be breaking changes that will require updates to your test scenarios. Please see the conclusion section of this blog to find out how to provide feedback to us.&lt;/p&gt; &lt;h2&gt;An automation testing framework built for the enterprise&lt;/h2&gt; &lt;p&gt;The latest Ansible Molecule developer preview is designed with Ansible Automation Platform and organizational level testing in mind. While it retains its core goal of providing a reliable way to make sure your automation is up to scratch, it's got some new tricks up its sleeve. Now, you can also test roles and playbooks within &lt;a href="https://docs.ansible.com/ansible/latest/dev_guide/developing_collections.html"&gt;Ansible Content Collections&lt;/a&gt;, making it even easier to develop and validate your automation content.&lt;/p&gt; &lt;p&gt;This update comes thanks to valuable feedback from our community of Molecule users. We've listened and made Molecule more user-friendly, especially for those who create and specialize in Ansible automation.&lt;/p&gt; &lt;p&gt;Here's a rundown of what's new and improved.&lt;/p&gt; &lt;h2&gt;Testing framework for content inside Ansible Content Collections&lt;/h2&gt; &lt;p&gt;Ansible Content Collections are a distribution format for Ansible content that can include playbooks, roles, modules, and plug-ins. They are used to distribute reusable Ansible content, enabling users to share, version, and distribute the building blocks of their automation.&lt;/p&gt; &lt;p&gt;Recognizing the complexity and interdependence of today's automation tasks, we have extended the capabilities of Molecule to test not just individual roles and playbooks but entire collections. This enhancement is particularly significant as we prepare for a seamless integration of Molecule into the Ansible Automation Platform.&lt;/p&gt; &lt;p&gt;The integration with Ansible Automation Platform positions Molecule as a future-ready tool. More importantly, it aligns with a user-friendly strategy for content testing within the platform. This approach aims to simplify the user experience, enabling both customers and community users to conduct comprehensive tests on their automation content in a manner that is consistent with the Ansible Automation Platform.&lt;/p&gt; &lt;h2&gt;Keeping it simple with one driver&lt;/h2&gt; &lt;p&gt;Ansible is now the default provisioner with this Molecule release. Molecule uses drivers as provisioners to create the infrastructure to run your tests on. Prior to the release of version 6, Molecule supported multiple drivers to provision testing instances using different technologies, including &lt;a href="https://developers.redhat.com/topics/linux/"&gt;Linux&lt;/a&gt; containers, virtual machines, and cloud providers. By default, it came with three pre-installed drivers: Docker and Podman drivers to manage &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt; and a delegated driver allowing you to customize your integration using Ansible. Drivers for other providers were available through the open source community.&lt;/p&gt; &lt;p&gt;The default and the only driver present with Ansible Molecule in Ansible Automation Platform is the delegated driver (aliased as "default" driver), which allows you to use Ansible itself to create and modify how Molecule provisions its test environments.&lt;/p&gt; &lt;p&gt;Ansible can automate various environments using the Ansible collections available through the community and Ansible Automation Platform. Because the delegated ("default") driver uses Ansible, we believe that it will help the adoption of Molecule as the testing framework for the enterprise.&lt;/p&gt; &lt;p&gt;Although using other drivers was a powerful approach that allowed customizations, this approach had its disadvantages. For instance, if you want to customize a driver's provisioning/de-provisioning mechanism, you will need to change the driver's source code, which means that you will need to go through the learning curve of writing Python code even if you are an Ansible playbook writer.&lt;/p&gt; &lt;h2&gt;Making the testinfra verifier optional&lt;/h2&gt; &lt;p&gt;In the context of Ansible Molecule, a "verifier" is a component responsible for running tests against the infrastructure or instances created during the testing process. The verifier is used to validate whether the Ansible role or playbook being tested has successfully achieved the desired state on the test instances. The verifier you choose determines the testing framework and syntax you use to write your tests.&lt;/p&gt; &lt;p&gt;Ansible is a powerful verifier and has been made the default verifier with Molecule 6. Testinfra is another popular verifier with Molecule, which has been made optional with Molecule 6. The testinfra library requires Molecule users to be proficient with &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt;, which limits its usability for many non-programmer IT practitioners. Making the Testinfra library optional with Molecule 6 is part of our efforts to refocus Molecule as a tool for functional testing of Ansible roles, collections, and playbooks using Ansible itself. Writing verifications can be done with native Ansible playbooks and tasks rather than using/learning a third-party tool with respect to Python.&lt;/p&gt; &lt;p&gt;What we mean by optional is that the testinfra Python library is not packaged as part of Molecule 6 for the downstream release. Rather, the testing "glue" is still available for testinfra in Molecule. For those IT practitioners who may be comfortable with Python and wish to use testinfra, it remains an installable option.&lt;/p&gt; &lt;h2&gt;Installing Molecule developer preview&lt;/h2&gt; &lt;p&gt;Molecule is packaged as part of the Ansible Automation Platform. You can &lt;a href="https://developers.redhat.com/products/ansible/download"&gt;download the bundled installer&lt;/a&gt; or &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_ansible_automation_platform/2.4/html/red_hat_ansible_automation_platform_planning_guide/proc-attaching-subscriptions_planning"&gt;subscribe to the Ansible Automation Platform repos&lt;/a&gt; to get access to the supported packages.&lt;/p&gt; &lt;p&gt;You can install Molecule using the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;dnf install \ --enablerepo=ansible-automation-platform-2.4-for-rhel-8-x86_64-rpms molecule&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Getting started with Molecule developer preview&lt;/h2&gt; &lt;p&gt;Let's take a look at how Molecule developer preview aligns more closely with Ansible content collection development and testing. All the examples here are available in the upstream Molecule &lt;a href="https://ansible.readthedocs.io/projects/molecule/getting-started/"&gt;project documentation&lt;/a&gt;.&lt;/p&gt; &lt;ol&gt;&lt;li&gt; &lt;p&gt;One of the recommended ways to create a collection is to place it under the &lt;code&gt;collections/ansible_collections&lt;/code&gt; directory:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;ansible-galaxy collection init foo.bar&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Navigate to the &lt;code&gt;roles&lt;/code&gt; directory in your new collection:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;cd &lt;path to your collection&gt;/foo.bar/roles/&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Initialize a new role for this collection:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;ansible-galaxy role init my_role&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Add a task under &lt;code&gt;my_role/tasks/main.yml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;--- - name: Task is running from within the role ansible.builtin.debug: msg: "This is a task from my_role." &lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Add Molecule to the content collection:&lt;/p&gt; &lt;ul&gt;&lt;li&gt; &lt;p&gt;Create a new directory in your collection called &lt;code&gt;extensions&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;code&gt;cd&lt;/code&gt; to the new &lt;code&gt;extensions&lt;/code&gt; directory:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;cd &lt;path to your collection&gt;/extensions/&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt; &lt;p&gt;Initialize the default Molecule scenario:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;molecule init scenario&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Edit the &lt;code&gt;molecule.yml&lt;/code&gt; file to use your local collection development environment as described. Add the following entry to your &lt;code&gt;&lt;path_to_your_collection&gt;/extensions/molecule/default/molecule.yml&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;provisioner: name: ansible config_options: defaults: collections_path: ${ANSIBLE_COLLECTIONS_PATH}&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Then, set the &lt;code&gt;ANSIBLE_COLLECTIONS_PATH&lt;/code&gt; environment variable at the command line before running Molecule:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;export ANSIBLE_COLLECTIONS_PATH=/home/user/working/collections&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note that the path should reflect the location up to the &lt;code&gt;collections&lt;/code&gt; directory and not the &lt;code&gt;ansible_collections&lt;/code&gt; directory.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Molecule scenarios&lt;/h2&gt; &lt;p&gt;Scenarios are the starting point for a lot of powerful functionality that Molecule offers. Think of a scenario as a test suite for roles or playbooks within a collection. You can have as many scenarios as you like, and Molecule will run them sequentially.&lt;/p&gt; &lt;h3&gt;The scenario layout&lt;/h3&gt; &lt;p&gt;Within the &lt;code&gt;molecule/default&lt;/code&gt; folder, we find several files:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ls create.yml destroy.yml molecule.yml converge.yml&lt;/code&gt;&lt;/pre&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;create.yml&lt;/code&gt; is a playbook file used for creating the instances and storing data in &lt;code&gt;instance-config&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;destroy.yml&lt;/code&gt; has the Ansible code for destroying the instances and removing them from &lt;code&gt;instance-config&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;molecule.yml&lt;/code&gt; is the central configuration entry point for Molecule per scenario. With this file, you can configure each tool that Molecule will employ when testing your role.&lt;/li&gt; &lt;li&gt;&lt;code&gt;converge.yml&lt;/code&gt; is the playbook file that contains the call for your role. Molecule will invoke this playbook with &lt;code&gt;ansible-playbook&lt;/code&gt; and run it against an instance created by the driver.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Inspecting the molecule.yml&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;molecule.yml&lt;/code&gt; is for configuring Molecule. It is a &lt;a href="https://yaml.org/"&gt;YAML&lt;/a&gt; file with keys that represent the high-level components that Molecule provides. These are:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;The &lt;a href="https://ansible.readthedocs.io/projects/molecule/configuration/#dependency"&gt;dependency&lt;/a&gt; manager:&lt;/strong&gt; Molecule uses &lt;a href="https://docs.ansible.com/ansible/latest/galaxy/dev_guide.html"&gt;galaxy development guide&lt;/a&gt; by default to resolve your role dependencies.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;The &lt;a href="https://ansible.readthedocs.io/projects/molecule/configuration/#platforms"&gt;platforms&lt;/a&gt; definitions:&lt;/strong&gt; Molecule relies on this to know which instances to create and name and which group each instance belongs to. If you need to test your role against multiple popular distributions (&lt;a href="https://developers.redhat.com/products/rhel/centos-and-rhel"&gt;CentOS&lt;/a&gt;, Fedora, Debian, &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt;), you can specify that in this section.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;The &lt;a href="https://ansible.readthedocs.io/projects/molecule/configuration/#provisioner"&gt;provisioner&lt;/a&gt;:&lt;/strong&gt; Molecule only provides an Ansible provisioner. Ansible manages the life cycle of the instance based on this configuration.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;The &lt;a href="https://ansible.readthedocs.io/projects/molecule/configuration/#scenario"&gt;scenario&lt;/a&gt; definition: &lt;/strong&gt;Molecule relies on this configuration to control the scenario sequence order.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;The &lt;a href="https://ansible.readthedocs.io/projects/molecule/configuration/#verifier"&gt;verifier&lt;/a&gt; framework:&lt;/strong&gt; Molecule uses Ansible by default to provide a way to write specific state-checking tests (such as deployment smoke tests) on the target instance.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Running a full test sequence&lt;/h3&gt; &lt;p&gt;Molecule provides commands to manually manage the lifecycle of the instance, scenario, development, and testing tools. However, we can also tell Molecule to manage this automatically within a scenario sequence.&lt;/p&gt; &lt;p&gt;&lt;code&gt;cd&lt;/code&gt; to the extensions directory:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;cd &lt;path to your collection&gt;/extensions/&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The full life cycle sequence can be invoked with &lt;code&gt;molecule test&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;Molecule full lifecycle sequence └── default ├── dependency ├── cleanup ├── destroy ├── syntax ├── create ├── prepare ├── converge ├── idempotence ├── side_effect ├── verify ├── cleanup └── destroy&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Testing the collection role&lt;/h3&gt; &lt;p&gt;One of the default files created as part of the initialization is the &lt;code&gt;converge.yml&lt;/code&gt; file. This file is a playbook created to run your role from start to finish. This can be modified if needed, but is a good place to start if you have never used Molecule before.&lt;/p&gt; &lt;p&gt;You now have an isolated test environment and can also use it for live development by running &lt;code&gt;molecule converge&lt;/code&gt;. It will run through the same steps as above but will stop after the &lt;code&gt;converge&lt;/code&gt; action. Then, you can make changes to your collection or the converge play, and then run &lt;code&gt;molecule converge&lt;/code&gt; again (and again) until you're done with your development work.&lt;/p&gt; &lt;p&gt;We can test the role by adding the following code to &lt;code&gt;converge.yml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;--- - name: Include a role from a collection hosts: localhost gather_facts: false tasks: - name: Testing role ansible.builtin.include_role: name: foo.bar.my_role tasks_from: main.yml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;code&gt;cd&lt;/code&gt; to the extensions directory:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;cd &lt;path to your collection&gt;/extensions/&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Run the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;molecule converge&lt;/code&gt;&lt;/pre&gt; &lt;div&gt;The above command runs the same steps as the molecule test for the default scenario but will stop after the converge action. This is beneficial if you want to keep the infrastructure up while you are doing your collections development work and testing.&lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;By introducing Ansible Molecule as a developer preview as part of an Ansible Automation Platform subscription, we are working towards ensuring the project is stable, supported, and maintainable in an enterprise environment.&lt;/p&gt; &lt;p&gt;If you have any questions or feedback on the changes, please reach out to the &lt;a href="https://github.com/ansible/molecule/issues/new/choose"&gt;Ansible Molecule project on Github&lt;/a&gt;. The project's maintainers will be happy to answer any questions on this topic.&lt;/p&gt; &lt;p&gt;As the project matures and evolves, we will keep you updated with more use cases for Ansible Molecule, including deep dives on testing with multiple operating systems, integrating Molecule with your &lt;a href="https://developers.redhat.com/topics/ci-cd/"&gt;CI/CD&lt;/a&gt; pipelines, and more.&lt;/p&gt; &lt;h2&gt;Where to go next&lt;/h2&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://ansible.readthedocs.io/projects/molecule/"&gt;Molecule project documentation&lt;/a&gt;: Check out the detailed documentation on the upstream molecule project that has a lot of getting started use cases with Molecule.&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/products/ansible/getting-started"&gt;Get hands-on with on-demand Ansible Automation Platform self-paced exercises&lt;/a&gt;. We have a variety of interactive in-browser exercises to experience Ansible Automation Platform in action.&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/products/ansible/download"&gt;Trial subscription&lt;/a&gt;: Are you ready to install on-premises? Get your own trial subscription for unlimited access to all the components of Ansible Automation Platform.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.youtube.com/ansibleautomation"&gt;Subscribe&lt;/a&gt; to the Red Hat Ansible Automation Platform YouTube channel.&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/09/13/introducing-ansible-molecule-ansible-automation-platform" title="Introducing Ansible Molecule with Ansible Automation Platform"&gt;Introducing Ansible Molecule with Ansible Automation Platform&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Anshul Behl</dc:creator><dc:date>2023-09-13T07:00:00Z</dc:date></entry><entry><title>How Red Hat enhances the developer experience</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/09/12/how-red-hat-enhances-developer-experience" /><author><name>Mithun T. Dhar</name></author><id>5e063440-428c-4394-98d8-ed28280c925b</id><updated>2023-09-12T18:00:00Z</updated><published>2023-09-12T18:00:00Z</published><summary type="html">&lt;p&gt;Hybrid and multicloud approaches offer developers more access to powerful computing resources than ever. However, this increasing complexity can make it challenging to manage all your development tasks, hindering productivity.&lt;/p&gt; &lt;p&gt;Red Hat's cloud-first approach simplifies modern cloud environments. Our versatile toolbox maintains flexibility and limits cloud vendor lock-in by letting you work with a wide range of cloud tools and vendors. Let's explore how Red Hat reduces friction by designing tools with developers in mind.&lt;/p&gt; &lt;h2&gt;Red Hat reduces friction for developers&lt;/h2&gt; &lt;p&gt;Red Hat's primary goal is to make it easier for you to create and deploy cloud-first applications. Our &lt;a href="https://www.redhat.com/en/topics/cloud/open-hybrid-cloud-approach"&gt;hybrid cloud approach&lt;/a&gt; builds on an &lt;a href="https://developers.redhat.com/topics/open-source-communities"&gt;open source&lt;/a&gt; foundation, enabling you to design software once and deploy it to any (or every) cloud platform.&lt;/p&gt; &lt;p&gt;Our commitment to open source software and cloud development means enabling &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; productivity, providing hosted offerings, and meeting you—the developer—where you are.&lt;/p&gt; &lt;h3&gt;Enabling container productivity&lt;/h3&gt; &lt;p&gt;A considerable portion of simplifying cloud-based development is facilitating container productivity. Central to this effort is &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;, a &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;-based platform that abstracts the intricacies of container management, allowing you to focus on coding instead of dealing with complex infrastructure.&lt;/p&gt; &lt;p&gt;With OpenShift, you can design containerized applications without learning Kubernetes or adjusting your code for specific infrastructure. Choose whether you want to self-manage your applications or have us do it for you. Then, deploy them with a flexible, hybrid-cloud approach, using a single UI to build code and deploy containers, regardless of the underlying infrastructure.&lt;/p&gt; &lt;h3&gt;Meeting developers where they are&lt;/h3&gt; &lt;p&gt;Red Hat's dedication to enhancing the developer experience extends to meeting developers where they're most comfortable. We understand that you have different preferences, so we've created solutions that seamlessly integrate into your existing work patterns.&lt;/p&gt; &lt;p&gt;Our integrated development environments (IDEs) offer code editing, debugging, and version control functions tailored to specific programming languages. The command-line interfaces (CLIs) provide a familiar and efficient way for you to interact with cloud resources and services, accessing the cloud's opportunities without a steep learning curve. Additionally, intuitive web UIs help you manage and monitor applications visually.&lt;/p&gt; &lt;p&gt;By choosing solutions that align with your preferences, you can work in a way that feels intuitive and natural. No need to constantly learn new tools.&lt;/p&gt; &lt;h3&gt;Effortless hosted solutions&lt;/h3&gt; &lt;p&gt;Red Hat provides various hosted offerings where you can experiment, innovate, and iterate seamlessly. Our cloud-hosted setups remove the hassles of provisioning, configuring, and maintaining infrastructure, so you can focus on creating applications.&lt;/p&gt; &lt;p&gt;Red Hat solutions encompass a range of services, from databases to application runtimes, each curated to align with your specific requirements. This approach helps you quickly deploy applications, gather feedback, and iterate rapidly, enabling a dynamic development cycle.&lt;/p&gt; &lt;h2&gt;Designing tools developers want to use&lt;/h2&gt; &lt;p&gt;Red Hat actively designs tools for developers to achieve more in hybrid cloud and multicloud settings.&lt;/p&gt; &lt;p&gt;For example, &lt;a href="https://developers.redhat.com/products/developer-hub/overview"&gt;Red Hat Developer Hub&lt;/a&gt;&lt;strong&gt; &lt;/strong&gt;is a customizable self-managed developer portal. Its self-service dashboard and data aggregation from multiple sources help seamlessly onboard developers and produce containerized applications. The portal includes &lt;a href="https://developers.redhat.com/products/plugins-for-backstage/overview"&gt;Red Hat Plug-ins for Backstage&lt;/a&gt;, a bundle of supported plug-ins for additional functions, ensuring a smoother overall experience.&lt;/p&gt; &lt;p&gt;Another developer tool, &lt;a href="http://developers.redhat.com/articles/2023/05/23/podman-desktop-now-generally-available"&gt;Podman Desktop&lt;/a&gt;, is a lightweight and efficient GUI application helping developers work with containers and Kubernetes from their local environments. Its user-friendly interface is helpful if you're new to containers. You can manage and share containerized applications from your computer, overseeing multiple containers at once without needing to recall complex command-line steps.&lt;/p&gt; &lt;p&gt;If you want to take these tools for a test drive, the &lt;a href="https://developers.redhat.com/developer-sandbox/"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt; is the fastest way to try Red Hat's products and technologies without setup or configuration. In the Developer Sandbox, you can freely experiment with Red Hat OpenShift, its vital developer tools, and cloud services. Guided tutorials and prebuilt sample applications help you learn by example from actual, production-ready services using Red Hat tooling. The Developer Sandbox also integrates with GitHub to import your source code.&lt;/p&gt; &lt;h2&gt;A comprehensive approach to boosting developer productivity&lt;/h2&gt; &lt;p&gt;Red Hat's commitment to the developer experience centers on providing a diverse toolkit so you can achieve your goals in the ever-evolving cloud landscape (Figure 1). Red Hat removes infrastructure complexities via our hosted offerings, simplifying the process of experimenting and iterating.&lt;/p&gt; &lt;p&gt;We seamlessly integrate our platform with IDEs, CLIs, and web UIs to cater to various developer preferences. Plus, Red Hat's emphasis on enabling container productivity, underscored by the OpenShift platform and its tooling, aligns with our dedication to streamlining developer workflows.&lt;/p&gt; &lt;p&gt;This comprehensive approach boosts efficiency while upholding Red Hat's commitment to open hybrid cloud development. Applications can flourish across diverse environments without constraints.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/developer-experience-red-hat.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/developer-experience-red-hat.png?itok=EMrvIwH4" width="600" height="515" alt="A Venn diagram of developer experience, made up of products, programs, and content." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: Red Hat's comprehensive approach to developer experience.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br /&gt;&lt;a href="https://developers.redhat.com/"&gt;Explore articles and other resources&lt;/a&gt; to learn about how Red Hat helps you do more.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/09/12/how-red-hat-enhances-developer-experience" title="How Red Hat enhances the developer experience"&gt;How Red Hat enhances the developer experience&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Mithun T. Dhar</dc:creator><dc:date>2023-09-12T18:00:00Z</dc:date></entry><entry><title>A Node.js success story at the electrical training ALLIANCE</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/09/12/nodejs-success-story-electrical-training-alliance" /><author><name>Michael Dawson</name></author><id>cb489f3b-c2e3-4654-810b-a1d47254da7e</id><updated>2023-09-12T07:00:00Z</updated><published>2023-09-12T07:00:00Z</published><summary type="html">&lt;p&gt;Red Hat and customers often work together as partners to help get an application across the finish line. In this article, Stephen (electrical training ALLIANCE) and Michael (Red Hat) share the story of one such collaboration that led to success with Node.js in production.&lt;/p&gt; &lt;h2&gt;The application&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://electricaltrainingalliance.org/"&gt;electrical training ALLIANCE&lt;/a&gt; (ETA) has the mission to develop educational materials for electrical workers. They do this by developing national standards for the education and training of electrical workers, creating standardized training curricula, and assisting in establishing local educational programs. A key part of this work is to develop and provide an application for the 275 training programs that will assist in the day-to-day operations supporting apprentices within the program from application through to graduation.&lt;/p&gt; &lt;h2&gt;Why Node.js?&lt;/h2&gt; &lt;p&gt;Node.js was a good fit for the training program application due to its natural affinity with the front end and because it allowed faster development and rollout along with streamlined user acceptance testing. &lt;a href="https://access.redhat.com/products/nodejs"&gt;The Red Hat build of Node.js&lt;/a&gt; was a choice that fit into&lt;a href="https://www.redhat.com/en/about/press-releases/electrical-training-alliance-selects-red-hats-managed-cloud-offerings-optimize-it-architecture"&gt; ETA's deployment strategy&lt;/a&gt; as it is Red Hat-maintained, supported, container ready, and runs well in &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;.  &lt;/p&gt; &lt;h2&gt;The journey&lt;/h2&gt; &lt;p&gt;Here we will summarize the process from initial development to deployment.&lt;/p&gt; &lt;h3&gt;Step 1: The CI/CD environment&lt;/h3&gt; &lt;p&gt;Working with Red Hat Consulting, the electrical training ALLIANCE settled on two OpenShift Dedicated clusters: one for non-production and one for production content. Tekton (openshift-pipelines) and Cockroach Cloud were chosen for the &lt;a href="https://developers.redhat.com/topics/ci-cd/"&gt;continuous integration and continuous deployment (CI/CD)&lt;/a&gt; platforms and for data persistence. Application images utilize Red Hat Quay and Red Hat &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt; for end-to-end Red Hat support and patching. These components are shown in Figure 1.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/eta1.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/eta1.png?itok=stlF6SB2" width="600" height="393" alt="ETA CI/CD infrastucture based on OpenShift" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: Infrastructure components include Tekton and Cockroach Cloud for CI/CD and data persistence and Red Hat Quay and containers for patching and support.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Step 2: Version 1 of the application using nginx and Node.js&lt;/h3&gt; &lt;p&gt;The project required a front-end and matching back-end for front-end (BFF) to help manage access to a number of existing services written in Quarkus. This is where Node.js came in as a fast and efficient stack on which to build the BFF. Conventional architecture led us to utilize an nginx container for reverse proxy and static asset hosting, along with a Node.js middleware container handling Red Hat OpenShift API Management, authentication, and authorization tasks. This architecture is shown in Figure 2.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/node-js-paper-v1.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/node-js-paper-v1.png?itok=mTQwarqQ" width="600" height="429" alt="ETA application V1" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Version 1 of the application with nginx and Node.js.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The initial version of the application exposed a key challenge due to how nginx must be built as an image (specifically the DNS resolution). There was no way to reuse the image between the non-production and production clusters described earlier, resulting in duplicate build pipelines with no guarantee that a build would succeed in production. This led the electrical training ALLIANCE to explore better options, resulting in version 2 of the application.&lt;/p&gt; &lt;h3&gt;Step 3: Version 2 of the application using Node.js and Next.js&lt;/h3&gt; &lt;p&gt;Since OpenShift provides load balancing, the electrical training ALLIANCE chose to remove nginx and migrate to a Next.js application backed by the Red Hat Node.js container. This allows for proper CI/CD where the image is built once in lower namespaces, tested, and promoted through to the production cluster with confidence.&lt;/p&gt; &lt;p&gt;Looking at existing documentation, however, it was not clear how to use Next.js with the &lt;a href="https://catalog.redhat.com/software/containers/search?q=node.js&amp;p=1"&gt;Red Hat Node.js container images&lt;/a&gt;. After reaching out for help, the electrical training ALLIANCE was pleased to discover that Red Hat had a dedicated &lt;a href="https://docs.google.com/presentation/d/1OVFVU-pWhWm6k5gM59lAI3OjFLOgxVXVECJDv-oSrRY/edit#slide=id.g229b1d01dd4_0_54"&gt;Node.js team&lt;/a&gt; who was happy to jump in and help figure this out. The end result was a solution using a two-stage Dockerfile, which you can read more about in &lt;a href="https://developers.redhat.com/articles/2022/11/23/how-deploy-nextjs-applications-red-hat-openshift"&gt;How to deploy Next.js applications to Red Hat OpenShift&lt;/a&gt;. This work resulted in the architecture shown in Figure 3.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/node-js-paper-v2.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/node-js-paper-v2.png?itok=248I27Gn" width="600" height="429" alt="ETA Node.js application V2" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: Version 2 of the Node.js application with Next.js.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Step 4: Production success&lt;/h3&gt; &lt;p&gt;The next step was production deployment, which is a great success with the applications already having 4,000 active users and potentially growing to 40,000 active users each year as it rolls out across all training locations.&lt;/p&gt; &lt;p&gt;In addition to supporting the initial applications, the Node.js solution was built as a pattern that can be reused for new products and the electrical training ALLIANCE is planning on rolling out many more.&lt;/p&gt; &lt;p&gt;So far, it has been used for the development and production of two products, which include:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;&lt;strong&gt;Training Administration System (TAS):&lt;/strong&gt; This product has a number of functions, including: &lt;ul&gt;&lt;li aria-level="2"&gt;First year online apprenticeship: This allows the electrical training ALLIANCE, partnered with ProTech Skills Institute, to deliver the first year of the apprenticeship's classroom training online. TAS manages the application process for the program, as well as the day-to-day management of the apprentices.&lt;/li&gt; &lt;li aria-level="2"&gt;&lt;strong&gt;Pre-apprenticeship:&lt;/strong&gt; This extends pre-apprenticeship to participating high school and trade schools.&lt;/li&gt; &lt;li aria-level="2"&gt;&lt;strong&gt;VEEP - Veterans to Electrician:&lt;/strong&gt; The &lt;a href="https://in2veep.com/about/"&gt;VEEP program&lt;/a&gt; will utilize TAS for the same purposes while supporting the path to apprenticeship from our veterans.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Curriculum analysis and mapping utility: &lt;/strong&gt;This product, developed for internal use, allows the electrical training ALLIANCE to map all of the curriculum against various industry requirements and evaluations to ensure the curriculum provided meets the needs of the industry.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Learn more&lt;/h2&gt; &lt;p&gt;To learn more about the electrical training ALLIANCE, check out &lt;a href="https://electricaltrainingalliance.org"&gt;electricaltrainingalliance.org&lt;/a&gt;. If you want to learn more about what Red Hat is up to on the Node.js front, visit our &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js page&lt;/a&gt;. &lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/09/12/nodejs-success-story-electrical-training-alliance" title="A Node.js success story at the electrical training ALLIANCE"&gt;A Node.js success story at the electrical training ALLIANCE&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Michael Dawson</dc:creator><dc:date>2023-09-12T07:00:00Z</dc:date></entry><entry><title>How to trigger jobs manually in Packit</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/09/08/how-trigger-jobs-manually-packit" /><author><name>Jakub Stejskal, David Kornel</name></author><id>13909259-cf88-4513-a5a4-851cb12e8e99</id><updated>2023-09-08T07:00:00Z</updated><published>2023-09-08T07:00:00Z</published><summary type="html">&lt;p&gt;Packit is an open source project aiming to ease your project's integration with Fedora &lt;a href="https://developers.redhat.com/topics/linux/"&gt;Linux&lt;/a&gt;, &lt;a href="https://developers.redhat.com/products/rhel/centos-and-rhel"&gt;CentOS Stream&lt;/a&gt;, and other distributions. Packit is mostly used by projects that build RPM packages. We won't go through the onboarding process that was already described in a &lt;a href="https://developers.redhat.com/articles/2022/08/16/how-set-packit-simplify-upstream-project-integration#"&gt;previous article&lt;/a&gt;, but we would like to introduce you to new features that were recently promoted into production.&lt;/p&gt; &lt;h2&gt;Testing Farm execution&lt;/h2&gt; &lt;p&gt;From Packit, you can easily trigger the tests on Testing Farm even without building the RPMs. This is very handy for projects that basically don't build RPMs but want to use these two services for verifying the code. As a good example, we can refer to the &lt;a href="https://strimzi.io/"&gt;Strimzi project&lt;/a&gt; where users consume &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; images.&lt;/p&gt; &lt;p&gt;In such cases, the users want to trigger the tests, verify the code and see some output. This option is available from the beginning. Users can easily define when to execute the tests for every pull request, commit, or release. That sounds pretty cool; however, when you have complex tests (5+ hours per test run) as we have in Strimzi, you probably don't want to trigger all tests for each commit. So, how can the users achieve that?&lt;/p&gt; &lt;h2&gt;Manual trigger&lt;/h2&gt; &lt;p&gt;We introduced a new configuration option &lt;code&gt;manual_trigger&lt;/code&gt; to enable triggering Packit jobs only manually. With this new configuration of Packit jobs, users can easily enable the manual trigger of a job, and this job is not automatically triggered when, for example, a new commit arrives to pull a request.&lt;/p&gt; &lt;p&gt;Users just need to specify &lt;code&gt;manual_trigger&lt;/code&gt; in the test's job description. Only boolean values are allowed with the default configuration set to &lt;code&gt;False&lt;/code&gt;. Examples of manual trigger configurations can be found in the &lt;a href="https://github.com/strimzi/strimzi-kafka-operator/blob/main/.packit.yaml"&gt;YAML file&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt; ... - job: tests trigger: pull_request identifier: "regression-operators" targets: - centos-stream-9-x86_64 - centos-stream-9-aarch64 skip_build: true manual_trigger: true labels: - regression - operators - regression-operators - ro tf_extra_params: test: fmf: name: regression-operators ... &lt;/pre&gt; &lt;p&gt;This new configuration allows users to onboard a new flow when a pull request is opened. For example, in draft mode, users push new commits and fixes, and when they are about to finish the pull request, they can easily type &lt;code&gt;/packit test&lt;/code&gt; as a pull request comment, and all jobs defined in &lt;code&gt;packit.yaml&lt;/code&gt; for the pull request are triggered.&lt;/p&gt; &lt;h2&gt;Labeling and identifying&lt;/h2&gt; &lt;p&gt;The solution just described is very easy to use; however, there might be use cases where the users don't want to trigger all the jobs. For example, when you have 10 jobs defined with different test scopes, you probably don't want to trigger acceptance and regression tests at the same time as acceptance could be a subset of regression.&lt;/p&gt; &lt;p&gt;Users now have two options for triggering a specific job. The first one is to trigger the job based on the identifier. When the user specifies &lt;code&gt;identifier: test-1&lt;/code&gt; in the job configuration, the Packit comment command for execution of the tests will look like this &lt;code&gt;/packit test –identifier test1&lt;/code&gt;. That command will execute jobs with this specific identifier, nothing else (Figure 1).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_2023-06-22_at_11.27.52.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_2023-06-22_at_11.27.52.png?itok=ofWtbNJ4" width="600" height="506" alt="Triggering jobs based on a specific identifier." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: Packit manual trigger 1.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;What if we want to execute more than one job? Users can use multiple identifiers in a comma-separated list, but it might be a little bit annoying to specify long identifiers every time. To add a better user experience, we've introduced &lt;code&gt;labels&lt;/code&gt; configuration that could group together multiple jobs. Command &lt;code&gt;/packit test –labels upgrade,regression&lt;/code&gt; will trigger all jobs that contain &lt;code&gt;upgrade&lt;/code&gt; or &lt;code&gt;regression&lt;/code&gt; in the list of labels in the job configuration.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_2023-06-22_at_11.30.38.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_2023-06-22_at_11.30.38.png?itok=jBRlKw9l" width="600" height="506" alt="Triggering a group of jobs via the label configuration." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Packit manual trigger 2.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;If you hesitated with onboarding to Packit due to the limitation of missing manual triggering of the jobs and missing labeling, you can start with onboarding now! As we already mentioned, Packit is an &lt;a href="https://devconfcz2023.sched.com/event/1MYme/become-an-open-source-service?linkback=grid"&gt;open source service&lt;/a&gt; and these improvements were done as contributions from outside of the Packit team. Everyone can contribute, so if you are missing some features, feel free to open a pull request.&lt;/p&gt; &lt;p&gt;To see more information about newly added options, check out the &lt;a href="https://packit.dev/docs/testing-farm/"&gt;documentation&lt;/a&gt;. If you are new to Packit, you can also watch talks from the Packit team from &lt;a href="https://devconfcz2023.sched.com/event/1MYlL/packit-rpm-integration-all-in-one?linkback=grid"&gt;DevConf 2023&lt;/a&gt; and &lt;a href="https://www.youtube.com/watch?v=e2aCilMy-5U"&gt;DevConf Mini 2023&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/09/08/how-trigger-jobs-manually-packit" title="How to trigger jobs manually in Packit"&gt;How to trigger jobs manually in Packit&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Jakub Stejskal, David Kornel</dc:creator><dc:date>2023-09-08T07:00:00Z</dc:date></entry></feed>
